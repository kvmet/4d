name: Wiki Sync to Pages

on:
  gollum:
  workflow_dispatch:
  push:
    branches:
      - main

jobs:
  sync-wiki:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout main repo
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Setup gh-pages branch
        run: |
          git fetch
          git checkout gh-pages || git checkout -b gh-pages
          git reset --hard origin/main
          rm -rf wiki
          rm -rf .github
          rm -f LICENSE
          rm -f .gitignore
          rm -f README.md
          # Commit the removals
          git config user.name "GitHub Actions Bot"
          git config user.email "<>"
          git add -A
          git commit -m "Remove files not needed in gh-pages"

      - name: Checkout wiki
        uses: actions/checkout@v3
        with:
          repository: ${{github.repository}}.wiki
          path: temp-wiki
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Install curl
        run: sudo apt-get install -y curl

      - name: Sync wiki content and images
        run: |
          # Clear out existing wiki folder
          rm -rf wiki
          mkdir -p wiki
          mkdir -p wiki/images

          # Process markdown files
          for file in temp-wiki/*.md; do
            if [ -f "$file" ]; then
              filename=$(basename "$file")
              if [[ "$filename" != "_"* ]]; then
                content=$(cat "$file")
                
                # Process GitHub attachment image tags
                while IFS= read -r line; do
                  if [[ $line =~ \<img.*src=\"(https://github\.com/[^\"]+)\".*\> ]]; then
                    img_url="${BASH_REMATCH[1]}"
                    
                    # Extract original file extension from URL or default to jpg if none found
                    file_extension=$(echo "$img_url" | grep -oP '\.[a-zA-Z]+$' || echo '.jpg')
                    img_filename=$(echo "$img_url" | md5sum | cut -d' ' -f1)${file_extension}

                    # Download the image with verbose output and proper redirect handling
                    echo "Downloading image from $img_url"
                    curl -L \
                         -H "Accept: image/*" \
                         -H "User-Agent: Mozilla/5.0" \
                         --verbose \
                         -o "wiki/images/$img_filename" "$img_url" 2>&1 | tee curl_output.log

                    echo "Curl exit code: $?"
                    echo "Downloaded file info:"
                    ls -l "wiki/images/$img_filename"
                    file "wiki/images/$img_filename"
                    
                    # Replace the entire <img> tag with markdown image syntax
                    if [[ $line =~ alt=\"([^\"]+)\" ]]; then
                      alt_text="${BASH_REMATCH[1]}"
                    else
                      alt_text="image"
                    fi
                    
                    new_img_tag="![${alt_text}](/wiki/images/${img_filename})"
                    
                    content="${content//$line/$new_img_tag}"
                  fi
                done <<< "$content"
                
                # Convert wiki-style links to markdown style without extension
                while IFS= read -r line; do
                  # Check for piped wiki links [[page|text]]
                  if [[ $line =~ \[\[(.*?)\|(.*?)\]\] ]]; then
                    link="${BASH_REMATCH[1]}"           # First capture group (page)
                    display="${BASH_REMATCH[2]}"        # Second capture group (text)
                    # Convert spaces to hyphens in link
                    link_with_hyphens="${link// /-}"
                    # Build markdown link
                    new_link="[${display}](${link_with_hyphens})"
                    # Replace in content
                    content="${content//${BASH_REMATCH[0]}/$new_link}"
                  # Check for simple wiki links [[page]]
                  elif [[ $line =~ \[\[(.*?)\]\] ]]; then
                    link="${BASH_REMATCH[1]}"
                    # Convert spaces to hyphens in link
                    link_with_hyphens="${link// /-}"
                    # Build markdown link
                    new_link="[${link}](${link_with_hyphens})"
                    # Replace in content
                    content="${content//${BASH_REMATCH[0]}/$new_link}"
                  fi
                done <<< "$content"
                
                # Check if file starts with frontmatter
                if [[ $(head -n 1 "$file") == "---" ]]; then
                  # Has frontmatter, but still process content for links
                  echo "$content" > "wiki/$(basename $file)"
                else
                  # Look for first H1 heading
                  if h1_title=$(echo "$content" | grep -m 1 "^# "); then
                    title=$(echo "$h1_title" | sed 's/^# //')
                    echo -e "---\ntitle: ${title}\nlayout: default\n---\n\n$content" > "wiki/$(basename $file)"
                  else
                    # No H1, just process content
                    echo "$content" > "wiki/$(basename $file)"
                  fi
                fi
              fi
            fi
          done

          # Clean up
          rm -rf temp-wiki
          
          # Configure git with token-based authentication
          git config user.name "GitHub Actions Bot"
          git config user.email "<>"
          git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${{ github.repository }}.git
          
          # Only add wiki directory, ignoring all dot files/directories
          git add wiki
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Sync wiki content and images"
            git push origin gh-pages --force
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
